#  ------------ General options ----------------------------------------
save_path = "/home/liujing/NFS/TPAMI_quantization/mutual/"
dataPath = "/home/liujing/Datasets" # path for loading data set
dataset = "cifar100" # options: imagenet | cifar10 | cifar100 | imagenet100 | mnist
nGPU = 1 # number of GPUs to use by default
GPU = 0  # default gpu to use, options: range(nGPU)
visible_devices = "3"

# ------------- Data options -------------------------------------------
nThreads = 4  # number of data loader threads

# ---------- Optimization options --------------------------------------
nEpochs = 200  # number of total epochs to train 400
batchSize = 128  # mini-batch size 128
momentum = 0.9  # momentum 0.9
weightDecay = 1e-4  # weight decay 1e-4

# lr master for optimizer 1 (mask vector d)
ori_opt_type = "SGD"
quan_opt_type = "SGD"
ori_lr = 0.1  # initial learning rate
quan_lr = 0.1
lrPolicy = "multi_step"  # options: multi_step | linear | exp | const | step
power = 0.98  # power for inv policy (lr_policy)
step = [80, 120]  # step for linear or exp learning rate policy
decayRate = 0.1 # lr decay rate
endlr = -1

# ---------- Model options ---------------------------------------------
netType = "PreResNet"  # options: ResNet | PreResNet | GreedyNet | NIN | LeNet5 | LeNet500300 | DenseNet_Cifar | AlexNet
experimentID = "noquanfirstlast_mutual_kl_0219"
teacher_depth = 20  # resnet depth: (n-2)%6==0
student_depth = 20
nClasses = 100  # number of classes in the dataset
wideFactor = 1  # wide factor for wide-resnet
drawNetwork = False

# ---------- Quantization options ---------------------------------------------
qw = [2, 4]
qa = [2, 4]
teacher_lambda = 1
student_lambda = 0.7
tloss_lambda = 0.5
sloss_lambda = 0.7
T = [1, 1]

# ---------- Resume or Retrain options ---------------------------------------------
resume = ""
ori_retrain = ""
quan_retrain = ""

repeat = 1